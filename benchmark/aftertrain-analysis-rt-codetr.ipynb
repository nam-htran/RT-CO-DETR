{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca5b1ad",
   "metadata": {
    "_cell_guid": "6dbc5875-e23e-4226-9dd5-98d48d5c507c",
    "_uuid": "ff98fd08-9c7a-43f6-b162-374099a52899",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-01T07:25:20.223180Z",
     "iopub.status.busy": "2025-11-01T07:25:20.222987Z",
     "iopub.status.idle": "2025-11-01T07:26:47.416114Z",
     "shell.execute_reply": "2025-11-01T07:26:47.415311Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 87.197639,
     "end_time": "2025-11-01T07:26:47.417655",
     "exception": false,
     "start_time": "2025-11-01T07:25:20.220016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m83.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics thop pycocotools pandas matplotlib seaborn faster_coco_eval\n",
    "!pip install -q \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a2facf",
   "metadata": {
    "_cell_guid": "6c913ab6-8f86-4c15-8921-ce6ee53dfcb9",
    "_uuid": "6dcaeab4-02d6-4afa-b8e0-6e98475cba3e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-01T07:26:47.459725Z",
     "iopub.status.busy": "2025-11-01T07:26:47.459488Z",
     "iopub.status.idle": "2025-11-01T07:26:48.213957Z",
     "shell.execute_reply": "2025-11-01T07:26:48.213245Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.77653,
     "end_time": "2025-11-01T07:26:48.215265",
     "exception": false,
     "start_time": "2025-11-01T07:26:47.438735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'RT-CO-DETR'...\r\n",
      "remote: Enumerating objects: 330, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (330/330), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (235/235), done.\u001b[K\r\n",
      "remote: Total 330 (delta 119), reused 301 (delta 90), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (330/330), 229.57 KiB | 6.56 MiB/s, done.\r\n",
      "Resolving deltas: 100% (119/119), done.\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!rm -rf /kaggle/working/RT-CO-DETR \n",
    "!git clone https://github.com/nam-htran/RT-CO-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b2dab0",
   "metadata": {
    "_cell_guid": "c341c695-2ba6-4065-91ed-41899d7a6754",
    "_uuid": "17ccd22f-829e-4fc0-a355-a2b1db59b3fa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-01T07:26:48.257826Z",
     "iopub.status.busy": "2025-11-01T07:26:48.257578Z",
     "iopub.status.idle": "2025-11-01T07:26:48.270290Z",
     "shell.execute_reply": "2025-11-01T07:26:48.269698Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035274,
     "end_time": "2025-11-01T07:26:48.271311",
     "exception": false,
     "start_time": "2025-11-01T07:26:48.236037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/RT-CO-DETR/final_benchmark.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/RT-CO-DETR/final_benchmark.py\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "import warnings\n",
    "import yaml\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# --- Cấu hình các đường dẫn CỐ ĐỊNH ---\n",
    "RTDETR_REPO_PATH = Path(\"/kaggle/working/RT-CO-DETR\")\n",
    "sys.path.insert(0, str(RTDETR_REPO_PATH / \"rtdetr\"))\n",
    "sys.path.insert(0, str(RTDETR_REPO_PATH))\n",
    "\n",
    "BASE_INPUT_PATH = Path(\"/kaggle/input/rt-co-detr-trained/RT-CO-DETR\")\n",
    "DATA_PATH = Path(\"/kaggle/input/dsp-pre-final/processed_taco_coco\")\n",
    "OUTPUT_PATH = Path(\"/kaggle/working/benchmark_output\")\n",
    "YOLO_DATA_PATH = OUTPUT_PATH / \"taco_yolo_for_eval\"\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "YOLO_DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    from thop import profile\n",
    "    from src.core import YAMLConfig\n",
    "except ImportError as e:\n",
    "    print(f\"Lỗi import: {e}.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Định nghĩa các mô hình ---\n",
    "MODELS_TO_BENCHMARK = OrderedDict({\n",
    "    \"RT-DETR (Distilled)\": { \"type\": \"rtdetr\", \"weights\": BASE_INPUT_PATH / \"output/FINETUNE_DISTILLED/best.pth\", \"config_template\": BASE_INPUT_PATH / \"templates/rtdetrv2_taco_finetune_distilled.yml.template\", \"generated_config\": OUTPUT_PATH / \"flat_distilled.yml\" },\n",
    "    \"RT-DETR (Baseline)\": { \"type\": \"rtdetr\", \"weights\": BASE_INPUT_PATH / \"output/FINETUNE_BASELINE/best.pth\", \"config_template\": BASE_INPUT_PATH / \"templates/rtdetrv2_taco_finetune_baseline.yml.template\", \"generated_config\": OUTPUT_PATH / \"flat_baseline.yml\" },\n",
    "    \"YOLOv11l (Baseline)\": { \"type\": \"yolo\", \"weights\": BASE_INPUT_PATH / \"output/YOLO/yolo_checkpoints/yolo11l_finetune_baseline/weights/best.pt\", \"config\": YOLO_DATA_PATH / \"taco_yolo.yaml\" }\n",
    "})\n",
    "\n",
    "# --- Các hàm tiện ích ---\n",
    "def print_header(title):\n",
    "    print(\"\\n\" + \"=\"*85 + f\"\\n| {title:^81} |\\n\" + \"=\"*85)\n",
    "\n",
    "def run_command(command, working_dir=None):\n",
    "    print(f\"\\n---> Đang thực thi: {' '.join(command)}\")\n",
    "    full_output = []\n",
    "    try:\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', cwd=working_dir)\n",
    "        for line in iter(process.stdout.readline, ''): print(line.strip()); full_output.append(line.strip())\n",
    "        process.wait()\n",
    "        print(f\"--- Lệnh {'thành công' if process.returncode == 0 else f'thất bại với mã lỗi {process.returncode}'} ---\")\n",
    "        return process.returncode, \"\\n\".join(full_output)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi thực thi lệnh: {e}\"); return -1, str(e)\n",
    "\n",
    "def parse_rtdetr_output(output_text):\n",
    "    metrics = {}\n",
    "    try:\n",
    "        ap_50_95 = re.search(r\"Average Precision\\s+\\(AP\\) @\\[ IoU=0.50:0.95 .* = ([\\d\\.]+)\", output_text)\n",
    "        ap_50 = re.search(r\"Average Precision\\s+\\(AP\\) @\\[ IoU=0.50\\s+.* = ([\\d\\.]+)\", output_text)\n",
    "        if ap_50_95: metrics['mAP50-95'] = float(ap_50_95.group(1))\n",
    "        if ap_50: metrics['mAP50'] = float(ap_50.group(1))\n",
    "    except Exception as e: print(f\"Không thể trích xuất chỉ số từ output RT-DETR: {e}\")\n",
    "    return metrics\n",
    "\n",
    "def merge_dicts(base, new):\n",
    "    for key, value in new.items():\n",
    "        if key in base and isinstance(base.get(key), dict) and isinstance(value, dict):\n",
    "            merge_dicts(base[key], value)\n",
    "        else:\n",
    "            base[key] = value\n",
    "    return base\n",
    "\n",
    "def find_include_file(filename, search_dir):\n",
    "    for root, _, files in os.walk(search_dir):\n",
    "        if filename in files:\n",
    "            return Path(root) / filename\n",
    "    return None\n",
    "\n",
    "def flatten_yaml_config_recursive(config_path, repo_config_root):\n",
    "    if not Path(config_path).exists():\n",
    "        print(f\"Cảnh báo: Không tìm thấy file config '{config_path}'\")\n",
    "        return {}\n",
    "    \n",
    "    with open(config_path, 'r') as f: config = yaml.safe_load(f) or {}\n",
    "    if '__include__' in config:\n",
    "        includes = config.pop('__include__')\n",
    "        base_config = {}\n",
    "        if isinstance(includes, str): includes = [includes]\n",
    "        for include_relative in includes:\n",
    "            include_filename = Path(include_relative).name\n",
    "            found_path = find_include_file(include_filename, repo_config_root)\n",
    "            if found_path:\n",
    "                included_data = flatten_yaml_config_recursive(found_path, repo_config_root)\n",
    "                base_config = merge_dicts(base_config, included_data)\n",
    "            else:\n",
    "                 print(f\"Cảnh báo: Không tìm thấy file include '{include_relative}' trong '{repo_config_root}'\")\n",
    "        return merge_dicts(base_config, config)\n",
    "    return config\n",
    "\n",
    "def generate_rtdetr_configs():\n",
    "    print(\"--- Tạo file config RT-DETR từ template ---\")\n",
    "    repo_config_root = RTDETR_REPO_PATH / \"rtdetr/configs\"\n",
    "    for name, model_info in MODELS_TO_BENCHMARK.items():\n",
    "        if model_info['type'] == 'rtdetr':\n",
    "            template_path, output_path = model_info['config_template'], model_info['generated_config']\n",
    "            flat_config = flatten_yaml_config_recursive(template_path, repo_config_root)\n",
    "            data_updates = {\n",
    "                'val_dataloader': {'dataset': {'img_folder': str(DATA_PATH / 'val2017'), 'ann_file': str(DATA_PATH / 'annotations/instances_val2017.json')}},\n",
    "                'train_dataloader': {'dataset': {'img_folder': str(DATA_PATH / 'train2017'), 'ann_file': str(DATA_PATH / 'annotations/instances_train2017.json')}},\n",
    "            }\n",
    "            flat_config = merge_dicts(flat_config, data_updates)\n",
    "            \n",
    "            # <<< SỬA LỖI: Đặt output_dir thành một chuỗi đơn giản >>>\n",
    "            flat_config['output_dir'] = str(OUTPUT_PATH / f\"temp_run_{name.replace(' ', '_')}\")\n",
    "            \n",
    "            flat_config.pop('tuning', None)\n",
    "\n",
    "            with open(output_path, 'w') as f: yaml.dump(flat_config, f, sort_keys=False, default_flow_style=False)\n",
    "            print(f\"Đã tạo file config (flattened) cho '{name}' tại: {output_path}\")\n",
    "\n",
    "def prepare_yolo_dataset_for_eval():\n",
    "    print_header(\"Chuẩn bị dữ liệu cho YOLO Evaluation\")\n",
    "    val_images_dir, val_labels_dir = YOLO_DATA_PATH / \"images/val\", YOLO_DATA_PATH / \"labels/val\"\n",
    "    if val_labels_dir.exists() and any(val_labels_dir.iterdir()):\n",
    "        print(\"...Dữ liệu YOLO đã tồn tại, bỏ qua bước chuẩn bị.\")\n",
    "        return\n",
    "    val_images_dir.mkdir(parents=True, exist_ok=True); val_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"... Sao chép ảnh validation\"); [shutil.copy(f, val_images_dir) for f in tqdm((DATA_PATH / \"val2017\").glob(\"*.jpg\"))]\n",
    "    print(\"... Chuyển đổi annotations sang định dạng YOLO\")\n",
    "    with open(DATA_PATH / \"annotations/instances_val2017.json\") as f: data = json.load(f)\n",
    "    images_info = {img['id']: img for img in data['images']}\n",
    "    for ann in tqdm(data['annotations']):\n",
    "        if (image_id := ann['image_id']) not in images_info: continue\n",
    "        img_info = images_info[image_id]; img_w, img_h = img_info['width'], img_info['height']\n",
    "        x, y, w, h = ann['bbox']; x_c, y_c, nw, nh = (x+w/2)/img_w, (y+h/2)/img_h, w/img_w, h/img_h\n",
    "        with open(val_labels_dir / (Path(img_info['file_name']).stem + \".txt\"), 'a') as f:\n",
    "            f.write(f\"{ann['category_id']} {x_c:.6f} {y_c:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
    "    with open(DATA_PATH / \"annotations/instances_train2017.json\") as f: coco_data = json.load(f)\n",
    "    class_names = [cat['name'] for cat in sorted(coco_data['categories'], key=lambda x: x['id'])]\n",
    "    yolo_yaml_path = MODELS_TO_BENCHMARK[\"YOLOv11l (Baseline)\"][\"config\"]\n",
    "    with open(yolo_yaml_path, 'w') as f: yaml.dump({'path': str(YOLO_DATA_PATH.absolute()), 'train': 'images/val', 'val': 'images/val', 'nc': len(class_names), 'names': class_names}, f, sort_keys=False)\n",
    "    print(f\"Đã tạo file YOLO YAML tại: {yolo_yaml_path}\")\n",
    "    \n",
    "def setup_and_verify_paths():\n",
    "    print_header(\"Bước 1: Chuẩn bị và Kiểm tra Files\")\n",
    "    generate_rtdetr_configs()\n",
    "    prepare_yolo_dataset_for_eval()\n",
    "    found_paths = OrderedDict()\n",
    "    for name, path_dict in MODELS_TO_BENCHMARK.items():\n",
    "        config_path = path_dict.get('generated_config', path_dict.get('config'))\n",
    "        if path_dict['weights'].exists() and config_path.exists():\n",
    "            print(f\"[SẴN SÀNG] {name}\")\n",
    "            found_paths[name] = path_dict\n",
    "        else:\n",
    "            print(f\"[BỎ QUA] {name} - Thiếu file.\")\n",
    "            if not path_dict['weights'].exists(): print(f\"  -> Thiếu weights: {path_dict['weights']}\")\n",
    "            if not config_path.exists(): print(f\"  -> Thiếu config: {config_path}\")\n",
    "    if not found_paths: print(\"\\nKhông có mô hình nào sẵn sàng. Dừng lại.\"); sys.exit(1)\n",
    "    print(\"\\n---> Tất cả các file cần thiết đã sẵn sàng!\")\n",
    "    return found_paths\n",
    "\n",
    "def evaluate_model_accuracy(paths, benchmark_results):\n",
    "    print_header(\"Bước 2: Đánh giá Độ chính xác (mAP trên tập Val)\")\n",
    "    for name, path_dict in paths.items():\n",
    "        print(f\"\\n--- Đang đánh giá: {name} ---\")\n",
    "        if name not in benchmark_results: benchmark_results[name] = {}\n",
    "        if path_dict[\"type\"] == \"rtdetr\":\n",
    "            command = [\"python\", str(RTDETR_REPO_PATH / \"rtdetr/tools/train.py\"), \"-c\", str(path_dict[\"generated_config\"]), \"-r\", str(path_dict[\"weights\"]), \"--test-only\"]\n",
    "            return_code, output = run_command(command, working_dir=RTDETR_REPO_PATH)\n",
    "            if return_code == 0: benchmark_results[name].update(parse_rtdetr_output(output))\n",
    "        elif path_dict[\"type\"] == \"yolo\":\n",
    "            model = YOLO(path_dict[\"weights\"])\n",
    "            results = model.val(data=str(path_dict[\"config\"]), imgsz=640, batch=16, split='val', verbose=False)\n",
    "            if results and hasattr(results, 'box'):\n",
    "                benchmark_results[name]['mAP50-95'] = results.box.map\n",
    "                benchmark_results[name]['mAP50'] = results.box.map50\n",
    "\n",
    "def analyze_model_complexity(paths, benchmark_results):\n",
    "    print_header(\"Bước 3: Phân tích Độ phức tạp (Params & FLOPs)\")\n",
    "    dummy_input = torch.randn(1, 3, 640, 640)\n",
    "    for name, path_dict in paths.items():\n",
    "        print(f\"\\n--- Đang phân tích: {name} ---\")\n",
    "        try:\n",
    "            model_cpu = None\n",
    "            config_file = path_dict.get('generated_config', path_dict.get('config'))\n",
    "            if path_dict[\"type\"] == \"rtdetr\":\n",
    "                cfg = YAMLConfig(config_file); model_cpu = cfg.model.cpu().eval()\n",
    "            elif path_dict[\"type\"] == \"yolo\":\n",
    "                model_cpu = YOLO(path_dict[\"weights\"]).model.cpu().eval()\n",
    "            if model_cpu:\n",
    "                macs, params = profile(model_cpu, inputs=(dummy_input.cpu(),), verbose=False)\n",
    "                benchmark_results[name]['Params (M)'] = params / 1e6; benchmark_results[name]['FLOPs (G)'] = macs * 2 / 1e9\n",
    "                print(f\"Params: {params / 1e6:.2f} M, FLOPs: {macs * 2 / 1e9:.2f} G\")\n",
    "        except Exception as e: print(f\"Lỗi khi phân tích {name}: {e}\")\n",
    "\n",
    "def measure_inference_speed(paths, benchmark_results):\n",
    "    print_header(\"Bước 4: Đo lường Tốc độ Suy luận\")\n",
    "    if not torch.cuda.is_available(): print(\"!!! CẢNH BÁO: Không tìm thấy GPU. Bỏ qua. !!!\"); return\n",
    "    device = torch.device(\"cuda\"); dummy_input = torch.randn(1, 3, 640, 640, device=device); warmup_runs, timed_runs = 20, 50\n",
    "    for name, path_dict in paths.items():\n",
    "        print(f\"\\n--- Đang đo: {name} ---\")\n",
    "        try:\n",
    "            model = None\n",
    "            config_file = path_dict.get('generated_config', path_dict.get('config'))\n",
    "            if path_dict[\"type\"] == \"rtdetr\":\n",
    "                cfg = YAMLConfig(config_file); model = cfg.model\n",
    "                state_dict = torch.load(path_dict[\"weights\"], map_location=device)\n",
    "                key = 'ema' if 'ema' in state_dict else 'model'\n",
    "                state = state_dict.get(key, {}).get('module', state_dict.get(key, state_dict))\n",
    "                model.load_state_dict(state); model = model.to(device).eval()\n",
    "            elif path_dict[\"type\"] == \"yolo\":\n",
    "                model = YOLO(path_dict[\"weights\"]).model.to(device).eval()\n",
    "            if model:\n",
    "                with torch.no_grad():\n",
    "                    for _ in tqdm(range(warmup_runs), desc=\"Warm-up\", leave=False): _ = model(dummy_input)\n",
    "                    torch.cuda.synchronize(); start_time = time.time()\n",
    "                    for _ in tqdm(range(timed_runs), desc=\"Timing\", leave=False): _ = model(dummy_input)\n",
    "                    torch.cuda.synchronize(); end_time = time.time()\n",
    "                avg_time_ms = (end_time - start_time) / timed_runs * 1000\n",
    "                benchmark_results[name]['Speed (ms)'] = avg_time_ms\n",
    "                print(f\"Tốc độ trung bình: {avg_time_ms:.2f} ms/ảnh\")\n",
    "        except Exception as e: print(f\"Lỗi khi đo tốc độ {name}: {e}\")\n",
    "\n",
    "def generate_final_summary(benchmark_results):\n",
    "    print_header(\"Bảng tổng kết Benchmark\")\n",
    "    df = pd.DataFrame.from_dict(benchmark_results, orient='index')\n",
    "    column_order = ['mAP50-95', 'mAP50', 'Speed (ms)', 'Params (M)', 'FLOPs (G)']\n",
    "    df = df.reindex(columns=column_order).dropna(axis=1, how='all')\n",
    "    for col in ['mAP50-95', 'mAP50']:\n",
    "        if col in df.columns: df[col] = df[col].map('{:.4f}'.format)\n",
    "    for col in ['Params (M)', 'FLOPs (G)', 'Speed (ms)']:\n",
    "        if col in df.columns: df[col] = df[col].map('{:.2f}'.format)\n",
    "    device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n",
    "    print(f\"Benchmark được thực hiện trên: {device_name}\\n\")\n",
    "    print(df.to_string())\n",
    "    summary_csv_path = OUTPUT_PATH / \"benchmark_summary.csv\"\n",
    "    df.to_csv(summary_csv_path); print(f\"\\nBảng tổng kết đã lưu tại: {summary_csv_path}\")\n",
    "    try:\n",
    "        df_plot = df.apply(pd.to_numeric, errors='coerce').dropna(subset=['Speed (ms)', 'mAP50-95'])\n",
    "        if df_plot.empty: print(\"Không có đủ dữ liệu để vẽ biểu đồ.\"); return\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sizes = (df_plot['Params (M)'] / df_plot['Params (M)'].max() * 600) + 150 if 'Params (M)' in df_plot else 200\n",
    "        scatter = ax.scatter(df_plot['Speed (ms)'], df_plot['mAP50-95'], s=sizes, c=df_plot.get('FLOPs (G)'), cmap='viridis_r', alpha=0.7, edgecolors=\"w\", linewidth=1.5)\n",
    "        for i, txt in enumerate(df_plot.index):\n",
    "            ax.annotate(txt, (df_plot['Speed (ms)'].iloc[i], df_plot['mAP50-95'].iloc[i]), xytext=(10, -10), textcoords='offset points', ha='left', arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=-0.2\", color='gray'))\n",
    "        ax.set_title('So sánh hiệu năng: Tốc độ vs. Độ chính xác', fontsize=16, weight='bold')\n",
    "        ax.set_xlabel('Thời gian suy luận (ms) - Càng thấp càng tốt', fontsize=12)\n",
    "        ax.set_ylabel('mAP @ .50-.95 - Càng cao càng tốt', fontsize=12)\n",
    "        ax.invert_xaxis()\n",
    "        if 'FLOPs (G)' in df_plot:\n",
    "            cbar = fig.colorbar(scatter, ax=ax, pad=0.01); cbar.set_label('FLOPs (G)', rotation=270, labelpad=20)\n",
    "        plot_path = OUTPUT_PATH / \"benchmark_plot.png\"\n",
    "        plt.savefig(plot_path, bbox_inches='tight'); print(f\"Biểu đồ so sánh đã lưu tại: {plot_path}\")\n",
    "    except Exception as e: print(f\"Không thể tạo biểu đồ: {e}\")\n",
    "\n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    benchmark_results = OrderedDict()\n",
    "    paths_to_benchmark = setup_and_verify_paths()\n",
    "    if paths_to_benchmark:\n",
    "        evaluate_model_accuracy(paths_to_benchmark, benchmark_results)\n",
    "        analyze_model_complexity(paths_to_benchmark, benchmark_results)\n",
    "        measure_inference_speed(paths_to_benchmark, benchmark_results)\n",
    "    generate_final_summary(benchmark_results)\n",
    "    print_header(\"QUY TRÌNH BENCHMARK HOÀN TẤT\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4733a56e",
   "metadata": {
    "_cell_guid": "5dcb9eba-77c5-4b6b-aa57-0839d502330a",
    "_uuid": "7d205827-6f6a-488f-8dd4-3769678bddd8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-01T07:26:48.312948Z",
     "iopub.status.busy": "2025-11-01T07:26:48.312747Z",
     "iopub.status.idle": "2025-11-01T07:28:49.149142Z",
     "shell.execute_reply": "2025-11-01T07:28:49.148330Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 120.858804,
     "end_time": "2025-11-01T07:28:49.150519",
     "exception": false,
     "start_time": "2025-11-01T07:26:48.291715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/RT-CO-DETR\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \r\n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\r\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761982017.157355      76 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761982017.211110      76 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                        Bước 1: Chuẩn bị và Kiểm tra Files                         |\r\n",
      "=====================================================================================\r\n",
      "--- Tạo file config RT-DETR từ template ---\r\n",
      "Đã tạo file config (flattened) cho 'RT-DETR (Distilled)' tại: /kaggle/working/benchmark_output/flat_distilled.yml\r\n",
      "Đã tạo file config (flattened) cho 'RT-DETR (Baseline)' tại: /kaggle/working/benchmark_output/flat_baseline.yml\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                       Chuẩn bị dữ liệu cho YOLO Evaluation                        |\r\n",
      "=====================================================================================\r\n",
      "... Sao chép ảnh validation\r\n",
      "225it [00:02, 83.95it/s]\r\n",
      "... Chuyển đổi annotations sang định dạng YOLO\r\n",
      "100%|██████████████████████████████████████| 776/776 [00:00<00:00, 25992.28it/s]\r\n",
      "Đã tạo file YOLO YAML tại: /kaggle/working/benchmark_output/taco_yolo_for_eval/taco_yolo.yaml\r\n",
      "[SẴN SÀNG] RT-DETR (Distilled)\r\n",
      "[SẴN SÀNG] RT-DETR (Baseline)\r\n",
      "[SẴN SÀNG] YOLOv11l (Baseline)\r\n",
      "\r\n",
      "---> Tất cả các file cần thiết đã sẵn sàng!\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                 Bước 2: Đánh giá Độ chính xác (mAP trên tập Val)                  |\r\n",
      "=====================================================================================\r\n",
      "\r\n",
      "--- Đang đánh giá: RT-DETR (Distilled) ---\r\n",
      "\r\n",
      "---> Đang thực thi: python /kaggle/working/RT-CO-DETR/rtdetr/tools/train.py -c /kaggle/working/benchmark_output/flat_distilled.yml -r /kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_DISTILLED/best.pth --test-only\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761982038.067740      92 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761982038.073954      92 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Not init distributed mode.\r\n",
      "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': 16, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': '/kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_DISTILLED/best.pth', 'tuning': None, 'epoches': 50, 'last_epoch': -1, 'use_amp': False, 'use_ema': False, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.0, 'find_unused_parameters': False, 'seed': None, 'print_freq': 100, 'checkpoint_freq': 5, 'output_dir': '/kaggle/working/benchmark_output/temp_run_RT-DETR_(Distilled)', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 60, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': '/kaggle/working/benchmark_output/temp_run_RT-DETR_(Distilled)', 'checkpoint_freq': 5, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': False, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': False, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, 'compile': True, 'epoches': 50, 'batch_size': 16, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)', 'lr': 1e-05}, {'params': '^(?=.*encoder)', 'lr': 1e-05}], 'lr': 0.0001, 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [40], 'gamma': 0.1}, 'config': '/kaggle/working/benchmark_output/flat_distilled.yml', 'resume': '/kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_DISTILLED/best.pth', 'test_only': True, 'print_method': 'builtin', 'print_rank': 0}}\r\n",
      "building val_dataloader with batch_size=32...\r\n",
      "Resume checkpoint from /kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_DISTILLED/best.pth\r\n",
      "Load last_epoch\r\n",
      "Load model.state_dict\r\n",
      "Load criterion.state_dict\r\n",
      "Load postprocessor.state_dict\r\n",
      "Test:  [0/8]  eta: 0:00:31    time: 3.9400  data: 1.6703  max mem: 4717\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.7893  data: 0.3023  max mem: 4728\r\n",
      "Test: Total time: 0:00:14 (1.8021 s / it)\r\n",
      "Averaged stats:\r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\r\n",
      "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\r\n",
      "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.378\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.446\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.677\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.864\r\n",
      "Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.801\r\n",
      "Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.749\r\n",
      "--- Lệnh thành công ---\r\n",
      "\r\n",
      "--- Đang đánh giá: RT-DETR (Baseline) ---\r\n",
      "\r\n",
      "---> Đang thực thi: python /kaggle/working/RT-CO-DETR/rtdetr/tools/train.py -c /kaggle/working/benchmark_output/flat_baseline.yml -r /kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_BASELINE/best.pth --test-only\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761982066.464206     116 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761982066.470561     116 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth\" to /root/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth\r\n",
      "Not init distributed mode.\r\n",
      "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': 16, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': '/kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_BASELINE/best.pth', 'tuning': None, 'epoches': 50, 'last_epoch': -1, 'use_amp': False, 'use_ema': False, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.0, 'find_unused_parameters': False, 'seed': None, 'print_freq': 100, 'checkpoint_freq': 5, 'output_dir': '/kaggle/working/benchmark_output/temp_run_RT-DETR_(Baseline)', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 60, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': '/kaggle/working/benchmark_output/temp_run_RT-DETR_(Baseline)', 'checkpoint_freq': 5, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': False, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': False, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': True}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, 'compile': True, 'epoches': 50, 'batch_size': 16, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)', 'lr': 1e-05}, {'params': '^(?=.*encoder)', 'lr': 1e-05}], 'lr': 0.0001, 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [40], 'gamma': 0.1}, 'config': '/kaggle/working/benchmark_output/flat_baseline.yml', 'resume': '/kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_BASELINE/best.pth', 'test_only': True, 'print_method': 'builtin', 'print_rank': 0}}\r\n",
      "\r\n",
      "0%|          | 0.00/90.0M [00:00<?, ?B/s]\r\n",
      "12%|█▏        | 11.1M/90.0M [00:00<00:00, 117MB/s]\r\n",
      "43%|████▎     | 38.9M/90.0M [00:00<00:00, 219MB/s]\r\n",
      "66%|██████▋   | 59.8M/90.0M [00:00<00:00, 158MB/s]\r\n",
      "85%|████████▍ | 76.2M/90.0M [00:00<00:00, 152MB/s]\r\n",
      "100%|██████████| 90.0M/90.0M [00:00<00:00, 164MB/s]\r\n",
      "Load PResNet50 state_dict\r\n",
      "building val_dataloader with batch_size=32...\r\n",
      "Resume checkpoint from /kaggle/input/rt-co-detr-trained/RT-CO-DETR/output/FINETUNE_BASELINE/best.pth\r\n",
      "Load last_epoch\r\n",
      "Load model.state_dict\r\n",
      "Load criterion.state_dict\r\n",
      "Load postprocessor.state_dict\r\n",
      "Test:  [0/8]  eta: 0:00:31    time: 3.9524  data: 1.9046  max mem: 4717\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.8047  data: 0.3142  max mem: 4728\r\n",
      "Test: Total time: 0:00:14 (1.8224 s / it)\r\n",
      "Averaged stats:\r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\r\n",
      "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300\r\n",
      "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\r\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.411\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632\r\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\r\n",
      "Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.740\r\n",
      "Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.614\r\n",
      "--- Lệnh thành công ---\r\n",
      "\r\n",
      "--- Đang đánh giá: YOLOv11l (Baseline) ---\r\n",
      "Ultralytics 8.3.223 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\r\n",
      "YOLO11l summary (fused): 190 layers, 25,325,572 parameters, 0 gradients, 86.8 GFLOPs\r\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 16.7MB/s 0.0s\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2603.8±725.2 MB/s, size: 216.3 KB)\r\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/benchmark_output/taco_yolo_for_eval/labels/val... 225 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 225/225 1.5Kit/s 0.2s\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/benchmark_output/taco_yolo_for_eval/labels/val.cache\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 15/15 1.6it/s 9.5s\r\n",
      "                   all        225        776       0.51      0.271      0.296      0.257\r\n",
      "Speed: 2.2ms preprocess, 32.5ms inference, 0.0ms loss, 0.7ms postprocess per image\r\n",
      "Results saved to \u001b[1m/kaggle/working/RT-CO-DETR/runs/detect/val\u001b[0m\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                  Bước 3: Phân tích Độ phức tạp (Params & FLOPs)                   |\r\n",
      "=====================================================================================\r\n",
      "\r\n",
      "--- Đang phân tích: RT-DETR (Distilled) ---\r\n",
      "Params: 40.92 M, FLOPs: 136.06 G\r\n",
      "\r\n",
      "--- Đang phân tích: RT-DETR (Baseline) ---\r\n",
      "Load PResNet50 state_dict\r\n",
      "Params: 40.92 M, FLOPs: 136.06 G\r\n",
      "\r\n",
      "--- Đang phân tích: YOLOv11l (Baseline) ---\r\n",
      "Params: 25.36 M, FLOPs: 87.53 G\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                         Bước 4: Đo lường Tốc độ Suy luận                          |\r\n",
      "=====================================================================================\r\n",
      "\r\n",
      "--- Đang đo: RT-DETR (Distilled) ---\r\n",
      "Tốc độ trung bình: 58.50 ms/ảnh\r\n",
      "\r\n",
      "--- Đang đo: RT-DETR (Baseline) ---\r\n",
      "Load PResNet50 state_dict\r\n",
      "Tốc độ trung bình: 59.68 ms/ảnh\r\n",
      "\r\n",
      "--- Đang đo: YOLOv11l (Baseline) ---\r\n",
      "Tốc độ trung bình: 30.87 ms/ảnh\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                              Bảng tổng kết Benchmark                              |\r\n",
      "=====================================================================================\r\n",
      "Benchmark được thực hiện trên: Tesla T4\r\n",
      "\r\n",
      "                    mAP50-95   mAP50 Speed (ms) Params (M) FLOPs (G)\r\n",
      "RT-DETR (Distilled)   0.2610  0.3100      58.50      40.92    136.06\r\n",
      "RT-DETR (Baseline)    0.2390  0.3000      59.68      40.92    136.06\r\n",
      "YOLOv11l (Baseline)   0.2566  0.2960      30.87      25.36     87.53\r\n",
      "\r\n",
      "Bảng tổng kết đã lưu tại: /kaggle/working/benchmark_output/benchmark_summary.csv\r\n",
      "Biểu đồ so sánh đã lưu tại: /kaggle/working/benchmark_output/benchmark_plot.png\r\n",
      "\r\n",
      "=====================================================================================\r\n",
      "|                           QUY TRÌNH BENCHMARK HOÀN TẤT                            |\r\n",
      "=====================================================================================\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/RT-CO-DETR\n",
    "!python final_benchmark.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8623325,
     "sourceId": 13574379,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8469591,
     "sourceId": 13441245,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 212.670709,
   "end_time": "2025-11-01T07:28:49.396135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-01T07:25:16.725426",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
